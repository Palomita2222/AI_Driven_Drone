{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8a9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import os\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c52d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "forward = \"fd\"\n",
    "right = \"rt\"\n",
    "left = \"lt\"\n",
    "right_rotate = \"rtr\"\n",
    "left_rotate = \"ltr\"\n",
    "\n",
    "forward_folder = f\"{os.path.join(path, forward)}\\\\\"\n",
    "right_folder = f\"{os.path.join(path, right)}\\\\\"\n",
    "left_folder = f\"{os.path.join(path, left)}\\\\\"\n",
    "rotate_right_folder = f\"{os.path.join(path, right_rotate)}\\\\\"\n",
    "rotate_left_folder = f\"{os.path.join(path, left_rotate)}\\\\\"\n",
    "\n",
    "folders = [forward_folder, right_folder, left_folder, rotate_right_folder, rotate_left_folder]\n",
    "\n",
    "recording_number = 25\n",
    "\n",
    "try:\n",
    "    os.mkdir(forward_folder)\n",
    "    os.mkdir(right_folder)\n",
    "    os.mkdir(left_folder)\n",
    "    os.mkdir(rotate_right_folder)\n",
    "    os.mkdir(rotate_left_folder)\n",
    "except:\n",
    "    pass\n",
    "#Instantiate cv2 cam (TAKES LESS NOW)\n",
    "cam = cv2.VideoCapture(0)#Put 1 if better webcam availiable\n",
    "width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "Images = np.empty((0, height, width))#set the image array to an empty one, with the shape of height width (To make the image shape)\n",
    "labels = np.empty(0)\n",
    "Lasers = np.empty((0, 5)) #Put 8 if 8 lasers in the end\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Blur the image\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 4)\n",
    "\n",
    "    # Sharpen the image\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]])\n",
    "    sharpened_image = cv2.filter2D(blurred_image, -1, kernel)\n",
    "\n",
    "    # Enhance contrast (optional)\n",
    "    clahe = cv2.createCLAHE(clipLimit=16.0, tileGridSize=(16, 16))\n",
    "    contrast_enhanced = clahe.apply(sharpened_image)\n",
    "\n",
    "    return contrast_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bed24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3466d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1(fd), 2(rt), 3(lt), 4(rtr), 5(ltr), 6(Train), 7(Test)6\n",
      "(120, 480, 640)\n",
      "(120,)\n",
      "(120, 5, 1)\n",
      "LASERS : [[[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]\n",
      "\n",
      " [[1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]\n",
      "  [5.]]],(108, 5, 1)\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1019.6489 - accuracy: 0.2315 - val_loss: 925.7148 - val_accuracy: 0.1667\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 464.6382 - accuracy: 0.1481 - val_loss: 51.4720 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 50.2999 - accuracy: 0.2870 - val_loss: 8.8703 - val_accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 3.4765 - accuracy: 0.8056 - val_loss: 8.8932 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 2.1599 - accuracy: 0.8241 - val_loss: 0.5668 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 3.1526e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 3.8483e-04 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 5.2501e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 8.3482e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 60ms/step - loss: 1.8841 - accuracy: 0.2037 - val_loss: 1.6912 - val_accuracy: 0.1667\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6528 - accuracy: 0.2037 - val_loss: 1.6238 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6716 - accuracy: 0.1944 - val_loss: 1.6134 - val_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6247 - accuracy: 0.1759 - val_loss: 1.6266 - val_accuracy: 0.1667\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6248 - accuracy: 0.1481 - val_loss: 1.6444 - val_accuracy: 0.1667\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6237 - accuracy: 0.2037 - val_loss: 1.6385 - val_accuracy: 0.1667\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6199 - accuracy: 0.1759 - val_loss: 1.6204 - val_accuracy: 0.1667\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6155 - accuracy: 0.2037 - val_loss: 1.6164 - val_accuracy: 0.1667\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6138 - accuracy: 0.1574 - val_loss: 1.6102 - val_accuracy: 0.1667\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6146 - accuracy: 0.1852 - val_loss: 1.6164 - val_accuracy: 0.1667\n",
      "4/4 [==============================] - 1s 261ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [3 2]\n",
      " [0 2]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [1 2]\n",
      " [3 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [3 2]\n",
      " [3 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [1 2]\n",
      " [0 2]\n",
      " [3 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [3 2]\n",
      " [3 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [3 2]\n",
      " [0 2]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [3 2]\n",
      " [3 2]\n",
      " [1 2]\n",
      " [4 2]\n",
      " [3 2]\n",
      " [0 2]\n",
      " [3 2]\n",
      " [3 2]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [3 2]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [0 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [4 2]\n",
      " [3 2]\n",
      " [1 2]\n",
      " [0 2]\n",
      " [4 2]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [1 2]\n",
      " [4 2]\n",
      " [3 2]\n",
      " [4 2]\n",
      " [3 2]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [0 2]\n",
      " [4 2]\n",
      " [1 2]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [3 2]\n",
      " [3 2]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [3 2]\n",
      " [4 2]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [3 2]\n",
      " [1 2]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [1 2]\n",
      " [4 2]\n",
      " [0 2]], shape=(108, 2), dtype=int64)\n",
      "108\n",
      "Predictions : (108, 2)\n",
      "Labels : (108,)\n",
      "Epoch 1/25\n",
      "4/4 [==============================] - 1s 2ms/step - loss: 1.5967 - accuracy: 0.3056\n",
      "Epoch 2/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3579 - accuracy: 0.5278\n",
      "Epoch 3/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1843 - accuracy: 0.5093\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0437 - accuracy: 0.4722\n",
      "Epoch 5/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.5000\n",
      "Epoch 6/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8513 - accuracy: 0.6204\n",
      "Epoch 7/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7878 - accuracy: 0.6944\n",
      "Epoch 8/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.8056\n",
      "Epoch 9/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.8704\n",
      "Epoch 10/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8889\n",
      "Epoch 11/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8889\n",
      "Epoch 12/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.9537\n",
      "Epoch 13/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.9444\n",
      "Epoch 14/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.9074\n",
      "Epoch 15/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9722\n",
      "Epoch 16/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9815\n",
      "Epoch 17/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9722\n",
      "Epoch 18/25\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.9722\n",
      "Epoch 19/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9907\n",
      "Epoch 20/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9907\n",
      "Epoch 21/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9815\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9907\n",
      "Epoch 23/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9907\n",
      "Epoch 25/25\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Image_Input with unsupported characters which will be renamed to image_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2DCNN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2DCNN\\assets\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Laser_Input with unsupported characters which will be renamed to laser_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1DCNN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1DCNN\\assets\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Combined_Input with unsupported characters which will be renamed to combined_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/FCNN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/FCNN\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1(fd), 2(rt), 3(lt), 4(rtr), 5(ltr), 6(Train), 7(Test)7\n",
      "[[[[ 59.]\n",
      "   [ 59.]\n",
      "   [ 59.]\n",
      "   ...\n",
      "   [103.]\n",
      "   [103.]\n",
      "   [103.]]\n",
      "\n",
      "  [[ 59.]\n",
      "   [ 59.]\n",
      "   [ 59.]\n",
      "   ...\n",
      "   [103.]\n",
      "   [103.]\n",
      "   [103.]]\n",
      "\n",
      "  [[ 59.]\n",
      "   [ 59.]\n",
      "   [ 59.]\n",
      "   ...\n",
      "   [103.]\n",
      "   [103.]\n",
      "   [103.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 81.]\n",
      "   [105.]\n",
      "   [130.]\n",
      "   ...\n",
      "   [ 25.]\n",
      "   [ 25.]\n",
      "   [ 25.]]\n",
      "\n",
      "  [[116.]\n",
      "   [130.]\n",
      "   [ 65.]\n",
      "   ...\n",
      "   [ 25.]\n",
      "   [ 25.]\n",
      "   [ 25.]]\n",
      "\n",
      "  [[116.]\n",
      "   [140.]\n",
      "   [ 72.]\n",
      "   ...\n",
      "   [ 25.]\n",
      "   [ 25.]\n",
      "   [ 25.]]]] (1, 480, 640, 1)\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "tf.Tensor([[3 1]], shape=(1, 2), dtype=int64) (1, 2)\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203131B28E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203131B28E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[1.7164488e-08 2.5218625e-09 1.3317399e-05 7.4529715e-02 9.2545694e-01]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "Images = np.empty((0, height, width))#set the image array to an empty one, with the shape of height width (To make the image shape)\n",
    "labels = np.empty(0)\n",
    "Lasers = np.empty((0, 5)) #Put 8 if 8 lasers in the end\n",
    "\n",
    "def image_sort(path):\n",
    "    images = []\n",
    "    for element in os.listdir(path):\n",
    "        if \".jpg\" in element:\n",
    "            images.append(element)\n",
    "    return images\n",
    "\n",
    "def text_sort(path):\n",
    "    texts = []\n",
    "    for element in os.listdir(path):\n",
    "        if \".txt\" in element:\n",
    "            texts.append(element)\n",
    "    return texts\n",
    "\n",
    "def folder_value(folder):\n",
    "    if folder == forward_folder:\n",
    "        return 0\n",
    "    elif folder == right_folder:\n",
    "        return 1\n",
    "    elif folder == left_folder:\n",
    "        return 2\n",
    "    elif folder == rotate_right_folder:\n",
    "        return 3\n",
    "    elif folder == rotate_left_folder:\n",
    "        return 4\n",
    "    else:\n",
    "        raise \"Problem with folder, the value given is not equal to a valid folder adress stated above!\"\n",
    "\n",
    "def rec_image(folder, times=1):\n",
    "    for i in range(times):\n",
    "        sleep(0.01)\n",
    "        ret, image = cam.read() #THE CAMERA SHOULD BE CONNECTED DIRECTLY TO JETSON NANO\n",
    "        image = preprocess_image(image)\n",
    "        cv2.imwrite(f\"{folder}{len(image_sort(folder))}.jpg\",image)\n",
    "\n",
    "def rec_lasers(folder, times=1):\n",
    "    #recieve lengths from 8 or 5 lasers\n",
    "    for i in range(times):\n",
    "        data = [1,2,3,4,5] #GET DATA FROM LASERS WITH JETSON NANO\n",
    "        file = open(f\"{folder}{len(text_sort(folder))}.txt\", \"w\")\n",
    "        file.write(str(data))\n",
    "        file.close()\n",
    "\n",
    "def read_data(folder):\n",
    "    global Images, labels, Lasers\n",
    "    for i in range(len(image_sort(folder))):\n",
    "        if i < len(image_sort(folder))-1:\n",
    "            image = cv2.imread(f\"{folder}{i+1}.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "            Images = np.append(Images, [image], axis=0)\n",
    "            labels = np.append(labels, folder_value(folder))\n",
    "    for i in range(len(text_sort(folder))):\n",
    "        if i < len(text_sort(folder))-1:\n",
    "            data = open(folder+text_sort(folder)[i],\"r\")\n",
    "            data = data.read().strip('][').split(', ')\n",
    "            Lasers = np.append(Lasers, [data], axis=0) # Load the LASER DATA\n",
    "            \n",
    "def process_predictions(tensor): #Has to be a numpy tensor, because tensorflow const cannot append\n",
    "    final_tensor = np.array([])\n",
    "    for prediction in tensor:\n",
    "        i = 1\n",
    "        for choice in prediction:\n",
    "            #print(choice)\n",
    "            if round(float(choice)) == 1:\n",
    "                final_tensor = np.concatenate((final_tensor, [i]))\n",
    "                #print(\"IT SHOULD CONCAT 1!\")\n",
    "            else:\n",
    "                i+=1\n",
    "    return tf.constant(np.round(final_tensor))\n",
    "\n",
    "def process_predictions_combined(predictions_image, predictions_laser):\n",
    "    max_indices_image = np.argmax(predictions_image, axis=1)\n",
    "    max_indices_laser = np.argmax(predictions_laser, axis=1)\n",
    "    \n",
    "    # Combine max indices for image and laser predictions\n",
    "    combined_indices = np.column_stack((max_indices_image, max_indices_laser))\n",
    "    \n",
    "    return tf.constant(np.round(combined_indices))\n",
    "                \n",
    "def train():\n",
    "    global Images, labels, Lasers\n",
    "    \n",
    "    for folder in folders:\n",
    "        read_data(folder)\n",
    "        \n",
    "    Lasers = Lasers.reshape((Lasers.shape[0], Lasers.shape[1], 1))\n",
    "\n",
    "    print(Images.shape)\n",
    "    print(labels.shape)\n",
    "    print(Lasers.shape)\n",
    "\n",
    "    # Split the data\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(Images, labels, test_size=0.1, random_state=21, stratify=labels)\n",
    "    train_lasers, test_lasers, _, _ = train_test_split(Lasers, labels, test_size=0.1, random_state=21, stratify=labels)\n",
    "    #print(f\"LASERS : {train_lasers},{train_lasers.shape}\")\n",
    "    #Preprocess the data\n",
    "    train_images = tf.expand_dims(train_images, axis=-1)\n",
    "    test_images = tf.expand_dims(test_images, axis=-1)\n",
    "    \n",
    "    train_images = tf.cast(train_images, dtype=tf.int32)\n",
    "    test_images = tf.cast(test_images, dtype=tf.int32)\n",
    "    \"\"\"    \n",
    "    train_lasers = tf.expand_dims(train_lasers, axis=-1)\n",
    "    train_lasers = tf.expand_dims(train_lasers, axis=-1)\"\"\"\n",
    "    \n",
    "    train_lasers = tf.strings.to_number(train_lasers, out_type=tf.float64)\n",
    "    test_lasers = tf.strings.to_number(test_lasers, out_type=tf.float64)\n",
    "    \n",
    "    train_labels = train_labels.astype(int)\n",
    "    test_labels = test_labels.astype(int)\n",
    "    laser_count = len(Lasers[0])\n",
    "    \n",
    "    print(f\"LASERS : {train_lasers},{train_lasers.shape}\")\n",
    "    # CONV2D\n",
    "    model1 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(height, width, 1), name=\"Image_Input\"),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.relu, name=\"Image_1_Conv2D\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name=\"Image_2_Pooling2D\"),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.relu, name=\"Image_3_Conv2D\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name=\"Image_4_Pooling2D\"),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.relu, name=\"Image_5_Conv2D\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2),name=\"Image_6_Pooling2D\"),\n",
    "        tf.keras.layers.Flatten(name=\"Image_7_Flatten\"),\n",
    "        tf.keras.layers.Dropout(0.5,name=\"Image_8_Dropout\"),\n",
    "        tf.keras.layers.Dense(5, activation=tf.keras.activations.softmax)\n",
    "        \n",
    "    ])\n",
    "    #CONV1D\n",
    "    model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(laser_count, 1), name=\"Laser_Input\"),\n",
    "        tf.keras.layers.Conv1D(32, kernel_size=3, activation=tf.keras.activations.relu, name=\"Laser_Conv1D\"),\n",
    "        tf.keras.layers.Flatten(name=\"Laser_flatten\"),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation=tf.keras.activations.softmax)\n",
    "    ])\n",
    "    #FC MODEL\n",
    "    model3 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=2, name=\"Combined_Input\"),\n",
    "        tf.keras.layers.Dense(32, activation=tf.keras.activations.relu, name=\"Combined_1_Dense\"),\n",
    "        tf.keras.layers.Dense(64, activation=tf.keras.activations.relu, name=\"Combined_2_Dense\"),\n",
    "        tf.keras.layers.Dropout(0.3, name=\"Combined_3_Dropout\"),\n",
    "        tf.keras.layers.Dense(5, activation=tf.keras.activations.softmax, name=\"Combined_OUTPUT\")\n",
    "    ])\n",
    "    #Compile and train the models\n",
    "    model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                          loss=tf.keras.losses.sparse_categorical_crossentropy, #Because it is category, mse is for numbers\n",
    "                          metrics=[\"accuracy\"])\n",
    "\n",
    "    model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "                          loss=tf.keras.losses.sparse_categorical_crossentropy, #Because it is category, mse is for numbers\n",
    "                          metrics=[\"accuracy\"])\n",
    "\n",
    "    model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "                          loss=tf.keras.losses.sparse_categorical_crossentropy, #Because it is category, mse is for numbers\n",
    "                          metrics=[\"accuracy\"])\n",
    "    #print(train_labels)\n",
    "    model1.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "    \"\"\"print(\"Train lasers shape:\", train_lasers.shape)\n",
    "    print(\"Test lasers shape:\", test_lasers.shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    model2.fit(train_lasers, train_labels, epochs=10, validation_data=(test_lasers, test_labels))\n",
    "    \n",
    "    predictions_model1 = model1.predict(train_images)\n",
    "    predictions_model2 = model2.predict(train_lasers)\n",
    "\n",
    "    # Concatenate predictions along the axis corresponding to models (axis=1)\n",
    "    \"\"\"print(len(train_images)+len(train_lasers))\n",
    "    print(\"LENGTH of predictions\",len(predictions))\n",
    "    print(\"LENGTH of predictions[0]\", len(predictions[0]))\n",
    "    print(np.array(predictions).shape)\n",
    "    print(predictions)\"\"\"\n",
    "    predictions = process_predictions_combined(predictions_model1, predictions_model2)\n",
    "    print(predictions)\n",
    "    print(len(predictions))\n",
    "    #predictions = process_predictions(predictions)\n",
    "    #predictions = predictions #- 1\n",
    "    print(f\"Predictions : {predictions.shape}\")\n",
    "    print(f\"Labels : {train_labels.shape}\")\n",
    "    \n",
    "    model3.fit(predictions-1, train_labels, epochs=25)\n",
    "    \n",
    "    model1.save(\"models/2DCNN\")\n",
    "    model2.save(\"models/1DCNN\")\n",
    "    model3.save(\"models/FCNN\")\n",
    "    return model1, model2, model3\n",
    "    \n",
    "    \n",
    "def test():\n",
    "    sleep(1)\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    ret, image = cam.read()\n",
    "    images = np.empty((0, height, width))\n",
    "    images = np.append(images, [preprocess_image(image)], axis=0)\n",
    "    images = images.reshape((1, 480, 640, 1))\n",
    "    print(images, images.shape)\n",
    "    lasers = np.array([[1, 2, 3, 4, 5]])\n",
    "    lasers = lasers.reshape((1,5,1))\n",
    "    \n",
    "    predictions_model1 = model1.predict(images)\n",
    "    predictions_model2 = model2.predict(lasers)\n",
    "    combined = process_predictions_combined(predictions_model1, predictions_model2)\n",
    "    combined = combined - 1\n",
    "    print(combined, combined.shape)\n",
    "\n",
    "    pred3 = model3.predict(combined)\n",
    "    print(pred3)\n",
    "    print(pred3.argmax())\n",
    "        \n",
    "for i in range(5):\n",
    "    main = input(\"1(fd), 2(rt), 3(lt), 4(rtr), 5(ltr), 6(Train), 7(Test)\")\n",
    "    #Instead of input, get values from recv\n",
    "    #Channel 1 to fwd\n",
    "    #Channel 2 to rt and lt (depends on the number)\n",
    "    #Channel 3 constant (set drone to hover / constant throttle)\n",
    "    #Channel 4 to rtr and ltr (depends on number)\n",
    "\n",
    "    if main == \"1\":\n",
    "        rec_image(forward_folder, recording_number)\n",
    "        rec_lasers(forward_folder, recording_number)\n",
    "    elif main == \"2\":\n",
    "        rec_image(right_folder, recording_number)\n",
    "        rec_lasers(right_folder, recording_number)\n",
    "    elif main == \"3\":\n",
    "        rec_image(left_folder, recording_number)\n",
    "        rec_lasers(left_folder, recording_number)\n",
    "    elif main == \"4\":\n",
    "        rec_image(rotate_right_folder, recording_number)\n",
    "        rec_lasers(rotate_right_folder, recording_number)\n",
    "    elif main == \"5\":\n",
    "        rec_image(rotate_left_folder, recording_number)\n",
    "        rec_lasers(rotate_left_folder, recording_number)\n",
    "    elif main == \"6\":\n",
    "        model1, model2, model3 = train()\n",
    "    elif main == \"7\":\n",
    "        test()\n",
    "    else:\n",
    "    \n",
    "        print(\"Not an option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "671de6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 16.   8. 139. ...   2.   2.   2.]\n",
      "  [166. 155. 139. ...  13.  13.  13.]\n",
      "  [123. 123. 123. ...  17.  17.  17.]\n",
      "  ...\n",
      "  [ 73.  73.  20. ... 173. 165. 165.]\n",
      "  [  8. 105.  28. ... 146. 131. 222.]\n",
      "  [ 11.   8.  28. ... 173. 146. 146.]]] (1, 480, 640)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "PREDICTION 1 :  <built-in method argmax of numpy.ndarray object at 0x0000017120764BD0>\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "tf.Tensor([1.], shape=(1,), dtype=float64) (1,)\n",
      "[[6.8907294e-04 9.6113437e-01 2.8489364e-04 3.7529521e-02 3.6209027e-04]] (1, 5) [[0.1991286  0.17713735 0.18953983 0.22320196 0.21099235]] (1, 5)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[0.03056177 0.09775604 0.48073006 0.24617979 0.14477228]]\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaabd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a2b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4fc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
